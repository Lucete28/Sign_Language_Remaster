{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"bvJ4QPGccEkc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700284855498,"user_tz":-540,"elapsed":20917,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}},"outputId":"4b795512-b9ee-45ca-99c4-636589bfee83"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tqdm import tqdm\n","import cv2\n","import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"nUBkzKn1c7JE","executionInfo":{"status":"ok","timestamp":1700284903514,"user_tz":-540,"elapsed":3970,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","print(device_lib.list_local_devices() )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjfmcRD4bwzI","executionInfo":{"status":"ok","timestamp":1700284906820,"user_tz":-540,"elapsed":660,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}},"outputId":"bc1a9921-a2b3-48ac-e6bc-ae982ae31867"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 14314282817620823300\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14410383360\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 4300859329806922105\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","xla_global_id: 416903419\n","]\n"]}]},{"cell_type":"code","source":["## 변수\n","PATH = '/content/drive/MyDrive/Sign_Remaster/Sign_Language_Remaster'"],"metadata":{"id":"0ffnDZKFfuvY","executionInfo":{"status":"ok","timestamp":1700284906820,"user_tz":-540,"elapsed":2,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"nbCW-ocUbUS_","executionInfo":{"status":"ok","timestamp":1700284971585,"user_tz":-540,"elapsed":64766,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}}},"outputs":[],"source":["def gan_load_and_preprocess_data(folder_path, target_frame_count=90, image_size=(128, 128), test_size=0.2, random_seed=42):\n","    data = []\n","\n","\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            cap = cv2.VideoCapture(video_path)\n","            frames = []\n","\n","            while cap.isOpened() and len(frames) < target_frame_count:\n","                ret, frame = cap.read()\n","                if not ret:\n","                    break\n","                resized_frame = cv2.resize(frame, image_size)\n","                frames.append(resized_frame)\n","\n","            # 프레임 수가 부족하면 패딩을 추가\n","            while len(frames) < target_frame_count:\n","                frames.append(np.zeros_like(frames[0]))\n","\n","            frames = np.array(frames)\n","\n","            data.append(frames)\n","\n","            cap.release()\n","    data = np.array(data) / 255.0\n","    return data\n","data = gan_load_and_preprocess_data(f'{PATH}/data/hello')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YyR9sFbnbUTB","executionInfo":{"status":"ok","timestamp":1700284971585,"user_tz":-540,"elapsed":10,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}},"outputId":"c7b92eeb-bb7f-4858-8e51-f562ab8bb14c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50, 90, 128, 128, 3)"]},"metadata":{},"execution_count":6}],"source":["data.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24pqj_zkbUTC","executionInfo":{"status":"ok","timestamp":1700285078471,"user_tz":-540,"elapsed":12717,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}},"outputId":"a4fa94f1-01d7-44d8-f416-c1c7ed0b59ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 전처리 완료\n"]}],"source":["\n","target_lable = 'hello'\n","def gan_load_and_preprocess_data(folder_path, target_frame_count=90, image_size=(128, 128), test_size=0.2, random_seed=42):\n","    data = []\n","\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".avi\"):\n","            video_path = os.path.join(folder_path, filename)\n","            cap = cv2.VideoCapture(video_path)\n","            frames = []\n","\n","            while cap.isOpened() and len(frames) < target_frame_count:\n","                ret, frame = cap.read()\n","                if not ret:\n","                    break\n","                resized_frame = cv2.resize(frame, image_size)\n","                # RGB를 그레이스케일로 변환\n","                gray_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)\n","                frames.append(gray_frame)\n","\n","            # 프레임 수가 부족하면 패딩을 추가\n","            while len(frames) < target_frame_count:\n","                frames.append(np.zeros_like(frames[0]))\n","\n","            frames = np.array(frames)\n","\n","            data.append(frames)\n","\n","            cap.release()\n","    data = np.array(data) / 255.0\n","    # 채널 차원 추가 (흑백으로 변환하면 채널이 1이 됨)\n","    data = np.expand_dims(data, axis=-1)\n","    return data\n","# 데이터 로드 및 전처리\n","data_dir = f'{PATH}/data/{target_lable}'\n","videos = gan_load_and_preprocess_data(data_dir)     # videos.shape ==(50, 90, 128, 128, 3)\n","print('데이터 전처리 완료')\n","\n","# 생성자 정의\n","def build_generator(latent_dim):\n","    model = Sequential()\n","    model.add(Dense(256, input_dim=latent_dim, activation='relu'))\n","    model.add(Dense(90*128*128*3, activation='sigmoid'))\n","    model.add(Reshape((90, 128, 128, 3)))\n","    return model\n","\n","# 판별자 정의\n","def build_discriminator(input_shape):\n","    model = Sequential()\n","    model.add(Flatten(input_shape=input_shape))\n","    model.add(Dense(1, activation='sigmoid'))\n","    return model\n","\n","\n","\n"]},{"cell_type":"code","source":["# GAN 모델 구성\n","latent_dim = 1\n","generator = build_generator(latent_dim)\n","discriminator = build_discriminator((90, 128, 128, 1))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":474},"id":"DL0PQuPQcbTO","executionInfo":{"status":"error","timestamp":1700285147726,"user_tz":-540,"elapsed":11433,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}},"outputId":"6f8ef211-83bb-42bb-9730-2e4aa9901255"},"execution_count":8,"outputs":[{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-beea78a53a45>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# GAN 모델 구성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-9de8a7fc69ae>\u001b[0m in \u001b[0;36mbuild_generator\u001b[0;34m(latent_dim)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m                 \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_fold_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             return tf.random.stateless_uniform(\n\u001b[0m\u001b[1;32m   2103\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                 \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: "]}]},{"cell_type":"code","source":["discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","discriminator.trainable = False\n","\n","gan_input = Input(shape=(latent_dim,))\n","x = generator(gan_input)\n","gan_output = discriminator(x)\n","\n","gan = Model(gan_input, gan_output)\n","gan.compile(loss='binary_crossentropy', optimizer=Adam())\n","\n","# GAN 모델 학습\n","epochs = 10000\n","batch_size = 1"],"metadata":{"id":"x153XhDN27Nu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('모델 학습 시작')\n","for e in tqdm(range(epochs)):\n","    for _ in range(videos.shape[0] // batch_size):\n","        # 실제 동영상 데이터 배치 추출\n","        idx = np.random.randint(0, videos.shape[0], batch_size)\n","        real_videos = videos[idx]\n","\n","        # 랜덤 노이즈 배치 생성\n","        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","\n","        # 가짜 동영상 데이터 생성\n","        generated_videos = generator.predict(noise)\n","\n","        # 실제 동영상과 가짜 동영상을 합치고 레이블 생성\n","        X = np.concatenate([real_videos, generated_videos])\n","        y_dis = np.zeros(2 * batch_size)\n","        y_dis[:batch_size] = 0.9  # 실제 동영상에 대한 레이블 부여\n","\n","        # 판별자 학습\n","        discriminator.trainable = True\n","        d_loss = discriminator.train_on_batch(X, y_dis)\n","\n","        # 생성자 학습\n","        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","        y_gen = np.ones(batch_size)\n","        discriminator.trainable = False\n","        g_loss = gan.train_on_batch(noise, y_gen)\n","\n","    # 중간 과정 출력\n","    if e % 100 == 0:\n","        print(f\"Epoch :{e}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")\n","\n","        # 생성된 동영상 저장\n","        if e % 1000 == 0:\n","            generated_videos = generated_videos * 255.0  # 정규화를 복원\n","            for i in range(generated_videos.shape[0]):\n","                np.save(f\"{PATH}/created_data/epoch_{e}_{target_lable}_{i}.npy\", generated_videos[i])\n","\n"],"metadata":{"id":"8h5Xhub3OCKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습된 모델 저장\n","generator.save(f\"{PATH}/model/generator_model.h5\")\n","discriminator.save(f\"{PATH}/model/discriminator_model.h5\")\n","gan.save(f\"{PATH}/model/gan_model.h5\")"],"metadata":{"id":"iKIuAxmeOGBC"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}