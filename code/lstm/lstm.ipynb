{"cells":[{"cell_type":"markdown","metadata":{"id":"f1DFLxYv750y"},"source":["# 데이터 전처리"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22001,"status":"ok","timestamp":1702356661634,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"},"user_tz":-540},"id":"OQYMO-8i7-vN","outputId":"76020abb-ef2c-4a17-e01e-2908d24c1061"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#import\n","import cv2\n","import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, MaxPooling3D, Flatten, Dense\n","from tqdm import tqdm"],"metadata":{"id":"RfydVTdOOoJo","executionInfo":{"status":"ok","timestamp":1702356666510,"user_tz":-540,"elapsed":4878,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42895,"status":"ok","timestamp":1702356709396,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"},"user_tz":-540},"id":"py60tVxd7501","outputId":"5ba91f87-d0e1-42b5-bc8d-8264ba3f6611"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 21/21 [00:10<00:00,  2.06it/s]\n","100%|██████████| 50/50 [00:31<00:00,  1.59it/s]\n","100%|██████████| 45/45 [00:00<00:00, 310433.68it/s]\n","100%|██████████| 124/124 [00:00<00:00, 587013.20it/s]\n"]}],"source":["\n","# 데이터 경로 설정\n","# bread_path = r'G:\\내 드라이브\\Sign_Remaster\\Sign_Language_Remaster\\data\\bread_house'\n","# hello_path = r'G:\\내 드라이브\\Sign_Remaster\\Sign_Language_Remaster\\data\\hello'\n","bread_path = r'/content/drive/MyDrive/Sign_Remaster/Sign_Language_Remaster/data/bread_house'\n","hello_path = r'/content/drive/MyDrive/Sign_Remaster/Sign_Language_Remaster/data/hello'\n","\n","# 함수: 영상 읽기 및 전처리\n","def read_and_preprocess_data(folder_path):\n","    data = []\n","    for filename in tqdm(os.listdir(folder_path)):\n","        if filename.endswith('.avi'):\n","            filepath = os.path.join(folder_path, filename)\n","            cap = cv2.VideoCapture(filepath)\n","            frames = []\n","            while True:\n","                ret, frame = cap.read()\n","                if not ret:\n","                    break\n","                # 영상 프레임을 128x128 크기로 resize하고 RGB로 변환\n","                frame = cv2.resize(frame, (128, 128))\n","                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","                frames.append(frame)\n","            cap.release()\n","            data.extend(frames)\n","    return data\n","\n","# 데이터 읽기 및 전처리\n","bread_data = read_and_preprocess_data(bread_path)\n","hello_data = read_and_preprocess_data(hello_path)\n","\n","# 시퀀스 길이 정의\n","sequence_length = 30  # 예시로 30프레임으로 고정\n","\n","# 데이터를 시퀀스 단위로 이어 붙이기\n","def create_sequences(data, sequence_length):\n","    sequences = []\n","    # num_sequences = len(data) // sequence_length\n","    num_sequences = len(data) // sequence_length\n","\n","    for i in tqdm(range(num_sequences)):\n","        sequence = data[i * sequence_length : (i + 1) * sequence_length]\n","        sequences.append(sequence)\n","\n","    return sequences\n","\n","# 시퀀스 생성\n","bread_sequences = create_sequences(bread_data, sequence_length)\n","hello_sequences = create_sequences(hello_data, sequence_length)\n","\n","# 텐서로 변환 (샘플 수, 프레임 수, 이미지 높이, 이미지 너비, 채널 수)\n","X_bread = np.array(bread_sequences).reshape(-1, sequence_length, 128, 128, 3)\n","X_hello = np.array(hello_sequences).reshape(-1, sequence_length, 128, 128, 3)\n","\n","# 레이블 설정\n","y_bread = np.zeros(len(X_bread))  # bread: 0\n","y_hello = np.ones(len(X_hello))   # hello: 1\n","\n","# 데이터 결합\n","X = np.concatenate((X_bread, X_hello))\n","y = np.concatenate((y_bread, y_hello))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":466,"status":"ok","timestamp":1701863255195,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"},"user_tz":-540},"id":"ro21QK0I7503","outputId":"bcf79917-d72c-4c8d-87f0-85bbe237afa4"},"outputs":[{"data":{"text/plain":["(169, 30, 128, 128, 3)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVa8JYZ77503","outputId":"bee994eb-d432-465b-c783-250b4579d528"},"outputs":[{"data":{"text/plain":["(169,)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["y.shape"]},{"cell_type":"markdown","metadata":{"id":"OngVUR2q7504"},"source":["# 모델 학습"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"1hsdGwTL7504","executionInfo":{"status":"ok","timestamp":1702356720138,"user_tz":-540,"elapsed":5974,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}}},"outputs":[],"source":["\n","# 모델 구축\n","model = Sequential([\n","    ConvLSTM2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', return_sequences=True, input_shape=(sequence_length, 128, 128, 3)),\n","    BatchNormalization(),\n","    MaxPooling3D(pool_size=(1, 2, 2)),\n","    ConvLSTM2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same', return_sequences=True),\n","    BatchNormalization(),\n","    MaxPooling3D(pool_size=(1, 2, 2)),\n","    Flatten(),\n","    Dense(256, activation='relu'),\n","    Dense(1, activation='sigmoid')  # 분류를 위한 출력 레이어\n","])\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJ3DbJCGPGLL","executionInfo":{"status":"ok","timestamp":1702354518199,"user_tz":-540,"elapsed":13,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}},"outputId":"431627f2-6aa4-4f78-eaa5-9a34e7900db2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv_lstm2d_2 (ConvLSTM2D)  (None, 30, 128, 128, 64   154624    \n","                             )                                   \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 30, 128, 128, 64   256       \n"," chNormalization)            )                                   \n","                                                                 \n"," max_pooling3d_2 (MaxPoolin  (None, 30, 64, 64, 64)    0         \n"," g3D)                                                            \n","                                                                 \n"," conv_lstm2d_3 (ConvLSTM2D)  (None, 30, 64, 64, 128)   885248    \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 30, 64, 64, 128)   512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling3d_3 (MaxPoolin  (None, 30, 32, 32, 128)   0         \n"," g3D)                                                            \n","                                                                 \n"," flatten_1 (Flatten)         (None, 3932160)           0         \n","                                                                 \n"," dense_2 (Dense)             (None, 256)               1006633216\n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 1007674113 (3.75 GB)\n","Trainable params: 1007673729 (3.75 GB)\n","Non-trainable params: 384 (1.50 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# 데이터 분할\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 제너레이터 생성 함수\n","def data_generator(features, labels, batch_size):\n","    num_samples = len(features)\n","    while True:\n","        for offset in range(0, num_samples, batch_size):\n","            batch_X = features[offset:offset+batch_size]\n","            batch_y = labels[offset:offset+batch_size]\n","            yield batch_X, batch_y\n","\n","# 하이퍼파라미터 설정\n","batch_size = 32\n","epochs = 10\n","\n","# 제너레이터 생성\n","train_generator = data_generator(X_train, y_train, batch_size)\n","val_generator = data_generator(X_val, y_val, batch_size)\n","\n","# 모델 학습\n","history = model.fit_generator(train_generator,\n","                              steps_per_epoch=len(X_train)//batch_size,\n","                              epochs=epochs,\n","                              validation_data=val_generator,\n","                              validation_steps=len(X_val)//batch_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TStVi2fmVHyd","outputId":"b866d3fe-073b-4894-dfce-2b5a95b3a381"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-868955587ec1>:24: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history = model.fit_generator(train_generator,\n"]}]},{"cell_type":"code","source":["# 모델 학습\n","model.fit(X, y, epochs=10, batch_size=16, validation_split=0.2)"],"metadata":{"id":"AfH9ulV_OiOa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["86.8 - 78.02"],"metadata":{"id":"yFZ2t-nFYycy","executionInfo":{"status":"ok","timestamp":1702357055864,"user_tz":-540,"elapsed":3,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"}},"outputId":"fc0f52f6-5eb9-42bd-e093-9b971ec4bc38","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8.780000000000001"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"Jk63ss2r7504"},"source":["# 테스트"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TsL62MP-7505"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","\n","# 저장된 모델 불러오기\n","model = load_model('path/to/your/model.h5')  # 학습된 모델의 경로를 설정해야 합니다.\n","\n","# 모델이 예측하는 클래스의 이름 설정\n","class_names = ['bread_house', 'hello']  # 각 클래스에 해당하는 이름을 설정해야 합니다.\n","\n","# 웹캠 또는 비디오 스트림 열기\n","cap = cv2.VideoCapture(0)  # 웹캠을 사용하려면 0을 입력하거나, 비디오 파일 경로를 입력하세요.\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # 프레임 전처리 (크기 조정 등)\n","    processed_frame = cv2.resize(frame, (128, 128))\n","    processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)\n","    processed_frame = np.expand_dims(processed_frame, axis=0)  # 모델에 입력하기 위해 차원 확장\n","\n","    # 모델로 예측\n","    prediction = model.predict(processed_frame)\n","    predicted_class = np.argmax(prediction)\n","\n","    # 예측 결과를 화면에 표시\n","    text = f\"Predicted: {class_names[predicted_class]}\"\n","    cv2.putText(frame, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","\n","    # 화면에 영상 표시\n","    cv2.imshow('Real-time Prediction', frame)\n","\n","    # 'q'를 누르면 종료\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# 작업 완료 후 해제\n","cap.release()\n","cv2.destroyAllWindows()\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.7"}},"nbformat":4,"nbformat_minor":0}