{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 1\n",
      "Number of hands detected: 2\n",
      "Number of hands detected: 2\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "No hands detected in this frame\n",
      "Shape of data: (199, 100)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture(r'G:\\내 드라이브\\Sign_Remaster\\Sign_Language_Remaster\\test_hands.mp4')  # 여기서 'video.mp4'는 사용할 영상 파일명입니다.\n",
    "data = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 영상을 RGB로 변환하여 Mediapipe에 전달\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(img_rgb)\n",
    "    \n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        print(f\"Number of hands detected: {len(results.multi_hand_landmarks)}\")\n",
    "        \n",
    "        for res in results.multi_hand_landmarks:\n",
    "            joint = np.zeros((21, 4))  # 21개의 관절에 대한 정보 저장 (x, y, z, visibility)\n",
    "\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[0, 1, 2, 3, 0, 5, 6, 7, 0, 9, 10, 11, 0, 13, 14, 15, 0, 17, 18, 19], :3]\n",
    "            v2 = joint[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], :3]\n",
    "            v = v2 - v1\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                                        v[[0, 1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18], :],\n",
    "                                        v[[1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19], :]))\n",
    "\n",
    "            angle = np.degrees(angle)\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, 1)  # Assuming idx is 1, change it accordingly\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "            data.append(d)\n",
    "\n",
    "            # mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "    else:\n",
    "        print(\"No hands detected in this frame\")\n",
    "    cv2.imshow('Hand Vector Data', img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 저장된 데이터 확인\n",
    "data = np.array(data)\n",
    "print(\"Shape of data:\", data.shape)\n",
    "\n",
    "# 데이터를 파일로 저장 (예: CSV 형태로)\n",
    "np.savetxt('hand_vector_data.csv', data, delimiter=',')  # 변경 가능한 파일명 및 형식입니다.\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 동영상으로 벡터 추출\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time, os\n",
    "\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "video_path = 'test_hands.mp4'  # 동영상 파일 경로\n",
    "\n",
    "action = input(\"녹화할 동작을 입력하세요: \")  # 사용자 입력으로 동작 받기\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)  # 동영상 파일을 VideoCapture 객체로 열기\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "    data = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while time.time() - start_time < secs_for_action:\n",
    "        ret, img = cap.read()\n",
    "\n",
    "        if not ret:  # 동영상이 끝나면 종료\n",
    "            break\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.multi_hand_landmarks is not None:\n",
    "            for res in result.multi_hand_landmarks:\n",
    "                joint = np.zeros((21, 4))\n",
    "                for j, lm in enumerate(res.landmark):\n",
    "                    joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "                v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3]\n",
    "                v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3]\n",
    "                v = v2 - v1\n",
    "                v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                    v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                    v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:]))\n",
    "                angle = np.degrees(angle)\n",
    "\n",
    "                angle_label = np.array([angle], dtype=np.float32)\n",
    "                angle_label = np.append(angle_label, action)  # 사용자가 입력한 동작 사용\n",
    "\n",
    "                d = np.concatenate([joint.flatten(), angle_label])\n",
    "                data.append(d)\n",
    "\n",
    "        if not ret:  # 동영상이 끝나면 종료\n",
    "            break\n",
    "\n",
    "    if len(data) == 0:  # 데이터가 없으면 종료\n",
    "        break\n",
    "\n",
    "    data = np.array(data)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "\n",
    "    break  # 여기서 영상 한 번만 실행하도록 설정\n",
    "\n",
    "cap.release()  # 비디오 캡처 객체 해제\n",
    "cv2.destroyAllWindows()  # 모든 창 닫기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOISE (437, 100)\n",
      "NOISE (407, 30, 100)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time, os\n",
    "\n",
    "actions = ['NOISE']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "# MediaPipe hands model\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "    for idx, action in enumerate(actions):\n",
    "        data = []\n",
    "\n",
    "        ret, img = cap.read()\n",
    "\n",
    "        img = cv2.flip(img, 1)\n",
    "\n",
    "        cv2.putText(img, f'Waiting for collecting {action.upper()} action...', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(3000)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        while time.time() - start_time < secs_for_action:\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            img = cv2.flip(img, 1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if result.multi_hand_landmarks is not None:\n",
    "                for res in result.multi_hand_landmarks:\n",
    "                    joint = np.zeros((21, 4))\n",
    "                    for j, lm in enumerate(res.landmark):\n",
    "                        joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "                    # Compute angles between joints\n",
    "                    v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "                    v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "                    v = v2 - v1 # [20, 3]\n",
    "                    # Normalize v\n",
    "                    v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                    # Get angle using arcos of dot product\n",
    "                    angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                        v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                        v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "                    angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "                    angle_label = np.array([angle], dtype=np.float32)\n",
    "                    angle_label = np.append(angle_label, idx)\n",
    "\n",
    "                    d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "                    data.append(d)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            cv2.imshow('img', img)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        data = np.array(data)\n",
    "        print(action, data.shape)\n",
    "        np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "        # Create sequence data\n",
    "        full_seq_data = []\n",
    "        for seq in range(len(data) - seq_length):\n",
    "            full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "        full_seq_data = np.array(full_seq_data)\n",
    "        print(action, full_seq_data.shape)\n",
    "        np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
