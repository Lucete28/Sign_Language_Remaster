{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# PATH = '/content/drive/MyDrive/Sign_Remaster/Sign_Language_Remaster'\n","PATH = 'G:/내 드라이브/Sign_Remaster/Sign_Language_Remaster'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2642,"status":"ok","timestamp":1701139009571,"user":{"displayName":"배재대정호연 2802","userId":"07214286366331303342"},"user_tz":-540},"id":"9DOPXEKTxKlI","outputId":"c8d1de11-cfc9-4f4c-bbc8-4191fbcc1ce8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv3d (Conv3D)             (None, 88, 126, 126, 32)  2624      \n","                                                                 \n"," max_pooling3d (MaxPooling3D  (None, 44, 63, 63, 32)   0         \n"," )                                                               \n","                                                                 \n"," conv3d_1 (Conv3D)           (None, 42, 61, 61, 64)    55360     \n","                                                                 \n"," max_pooling3d_1 (MaxPooling  (None, 21, 30, 30, 64)   0         \n"," 3D)                                                             \n","                                                                 \n"," conv3d_2 (Conv3D)           (None, 19, 28, 28, 64)    110656    \n","                                                                 \n"," max_pooling3d_2 (MaxPooling  (None, 9, 14, 14, 64)    0         \n"," 3D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 112896)            0         \n","                                                                 \n"," dense (Dense)               (None, 64)                7225408   \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 7,394,178\n","Trainable params: 7,394,178\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","# 모델 파일 불러오기    ### test10.h5   test2.h5\n","model = load_model(r\"C:\\Users\\2580j\\Downloads\\test2.h5\")\n","# model = load_model(f'{PATH}/model/test10.h5')\n","model.summary()\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["bread_house\n","90\n","None\n","90\n","None\n","90\n","None\n","90\n","None\n","90\n","None\n","90\n","None\n","90\n","None\n","90\n","None\n","90\n","None\n"]}],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","from IPython.display import clear_output\n","from collections import deque\n","num = 0\n","cap = cv2.VideoCapture(0)\n","mp_hands = mp.solutions.hands\n","mp_drawing = mp.solutions.drawing_utils\n","hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n","target_frames = 90\n","\n","# target_frames프레임을 담을 빈 배열 초기화\n","# video_frames = [np.zeros((128, 128, 3), dtype=np.float32) for _ in range(target_frames)]\n","frame_count = 0  # 현재까지 저장된 프레임 수\n","\n","video_frames = deque()\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    frame = cv2.flip(frame, 1)\n","    if not ret:\n","        continue\n","\n","    # 손 감지 및 랜드마크 추출\n","    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","\n","    # 검은색 배경 생성\n","    hand_landmarks_image = np.zeros_like(frame)\n","\n","    if results.multi_hand_landmarks:\n","        for hand_landmarks in results.multi_hand_landmarks:\n","            # 손 랜드마크를 화면에 표시\n","            mp_drawing.draw_landmarks(hand_landmarks_image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n","                                      landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2),\n","                                      connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2))\n","\n","    # 이미지를 전처리하고 비디오 프레임 배열에 추가\n","    resized_image = cv2.resize(hand_landmarks_image, (128, 128))  # 입력 크기에 맞게 조정\n","    resized_image = resized_image / 255.0  # 정규화\n","    predicted_label = None\n","    \n","    # # 현재 프레임을 빈 배열에 추가\n","    # target_index = frame_count % target_frames\n","    # video_frames[target_index] += resized_image\n","    frame_count += 1\n","    \n","    video_frames.append(resized_image)\n","\n","    # target_frames프레임이 모였을 때 모델에 전달하여 예측\n","    if len(video_frames) >= target_frames:\n","        print(len(video_frames))\n","        input_video = np.array(video_frames)  # target_frames프레임을 4D 배열로 변환\n","        input_video = np.expand_dims(input_video, axis=0)  # 배치 차원 추가\n","\n","        # 모델에 예측 요청\n","        if frame_count %10 ==0:\n","            pred = model.predict(input_video)  \n","            # 출력 지우기\n","            clear_output(wait=True)\n","            # 예측된 클래스를 확인하고 라벨 출력\n","            predicted_class = np.argmax(pred, axis=1)  # 확률이 가장 높은 클래스의 인덱스 가져오기\n","            if predicted_class == 0:\n","                predicted_label = \"hello\"\n","            else:\n","                predicted_label = \"bread_house\"\n","        video_frames.popleft()\n","\n","    # 화면에 예측된 라벨 텍스트 출력\n","    cv2.putText(frame, f\"Predicted Label: {predicted_label}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n","    print(predicted_label)\n","    cv2.imshow('Video', frame) # 동영상 보이기\n","    # cv2.imshow('Video', hand_landmarks_image) # 랜드마크 보이기\n","\n","    # 종료\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["(128, 128, 3)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.7"}},"nbformat":4,"nbformat_minor":0}
