{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import getsizeof\n",
    "from pympler import asizeof\n",
    "import pandas as pd\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "# 카메라 캡처를 초기화합니다.\n",
    "cap = cv2.VideoCapture(0)  # 0은 기본 카메라를 의미합니다.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "# 녹화 상태를 나타내는 변수를 초기화합니다.\n",
    "recording = False\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 비디오 코덱을 설정합니다.\n",
    "out = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    with mp_hands.Hands(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "        # 카메라에서 프레임을 읽어옵니다.\n",
    "        ret, frame = cap.read()\n",
    "        success, image = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    #     # 프레임을 화면에 표시합니다.\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # 's' 키를 누르면 녹화를 시작합니다.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            recording = True\n",
    "            out = cv2.VideoWriter('output.avi', fourcc, 20.0, (frame.shape[1], frame.shape[0]))  # 출력 파일을 설정합니다.\n",
    "\n",
    "        # 녹화 중일 때 프레임을 저장합니다.\n",
    "        if recording:\n",
    "            out.write(frame)\n",
    "\n",
    "        # 't' 키를 누르면 녹화를 중지하고 저장 파일을 닫습니다.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('t'):\n",
    "            if recording:\n",
    "                recording = False\n",
    "                out.release()  # 녹화 파일을 닫습니다.\n",
    "                print(\"녹화가 종료되었습니다.\")\n",
    "        \n",
    "        # 'q' 키를 누르면 루프를 종료합니다.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 카메라 캡처를 해제하고 창을 닫습니다.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = None\n",
    "recording = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # 화면에 손 감지된 랜드마크 표시\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    if results.multi_hand_landmarks:\n",
    "        for landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # 녹화 시작\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        recording = True\n",
    "        out = cv2.VideoWriter('output.avi', fourcc, 20.0, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # 녹화 중지 및 파일 저장\n",
    "    if cv2.waitKey(1) & 0xFF == ord('t'):\n",
    "        if recording:\n",
    "            recording = False\n",
    "            out.release()\n",
    "            print(\"녹화가 종료되었습니다.\")\n",
    "\n",
    "    # 녹화 중일 때 프레임 저장\n",
    "    if recording:\n",
    "        out.write(frame)\n",
    "\n",
    "    # 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = None\n",
    "recording = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # 손 감지 및 랜드마크 추출\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # 손 랜드마크만 추출하여 이진 이미지 생성 (손의 랜드마크만 흰색으로, 배경은 검은색으로)\n",
    "            hand_landmarks_image = np.zeros_like(frame)\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                cv2.circle(hand_landmarks_image, (x, y), 5, (255, 255, 255), -1)\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # 녹화 시작\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        recording = True\n",
    "        out = cv2.VideoWriter('output.avi', fourcc, 20.0, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # 녹화 중지 및 파일 저장\n",
    "    if cv2.waitKey(1) & 0xFF == ord('t'):\n",
    "        if recording:\n",
    "            recording = False\n",
    "            out.release()\n",
    "            print(\"녹화가 종료되었습니다.\")\n",
    "\n",
    "    # 녹화 중일 때 프레임 저장\n",
    "    if recording:\n",
    "        out.write(hand_landmarks_image)\n",
    "\n",
    "    # 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = None\n",
    "recording = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # 손 감지 및 랜드마크 추출\n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # 손 랜드마크만 추출하여 이진 이미지 생성 (손의 랜드마크만 흰색으로, 배경은 검은색으로)\n",
    "            hand_landmarks_image = np.zeros_like(frame)\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                cv2.circle(hand_landmarks_image, (x, y), 5, (255, 255, 255), -1)\n",
    "\n",
    "            # 랜드마크 간의 선 그리기\n",
    "            connections = mp_hands.HAND_CONNECTIONS\n",
    "            for connection in connections:\n",
    "                connection_point_a = tuple(\n",
    "                    np.multiply([hand_landmarks.landmark[connection[0]].x, hand_landmarks.landmark[connection[0]].y],\n",
    "                                [frame.shape[1], frame.shape[0]]).astype(int))\n",
    "                connection_point_b = tuple(\n",
    "                    np.multiply([hand_landmarks.landmark[connection[1]].x, hand_landmarks.landmark[connection[1]].y],\n",
    "                                [frame.shape[1], frame.shape[0]]).astype(int))\n",
    "                cv2.line(hand_landmarks_image, connection_point_a, connection_point_b, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Video', hand_landmarks_image)\n",
    "\n",
    "    # 녹화 시작\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        recording = True\n",
    "        out = cv2.VideoWriter('output.avi', fourcc, 20.0, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # 녹화 중지 및 파일 저장\n",
    "    if cv2.waitKey(1) & 0xFF == ord('t'):\n",
    "        if recording:\n",
    "            recording = False\n",
    "            out.release()\n",
    "            print(\"녹화가 종료되었습니다.\")\n",
    "\n",
    "    # 녹화 중일 때 프레임 저장\n",
    "    if recording:\n",
    "        out.write(hand_landmarks_image)\n",
    "\n",
    "    # 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
